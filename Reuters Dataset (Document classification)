import matplotlib.pyplot as plt
import numpy as np
%matplotlib inline
import tensorflow as tf
from tensorflow.keras.datasets import reuters
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping

(x_train,y_train) , (x_test,y_test) = reuters.load_data( num_words=10000, test_split=0.2) #each examples contains sequence of numbers, x_train.shape = (8982,)
num_classes = np.max(y_train)+1 #due to zero indexing in y_train

#vectorize sequence data and one-hot encode class labels
tokenizer = Tokenizer(num_words=10000)
x_train = tokenizer.sequences_to_matrix(x_train,mode='binary') #x_train.shape = (8982,10000)
x_test = tokenizer.sequences_to_matrix(x_test,mode='binary') #x_test.shape = (2246,10000)

y_train = to_categorical(y_train,num_classes)
y_test = to_categorical(y_test,num_classes)

model = Sequential([Dense(512,input_shape=(10000,)),
        Activation('relu'),
        Dropout(0.5),
        Dense(num_classes),
        Activation('softmax')
])
model.summary()

es = EarlyStopping(monitor='val_loss',patience=3, verbose=1,mode='min')

model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])

model.fit(x_train,y_train,callbacks=[es], epochs=100, batch_size=32, validation_split=0.1)

model.evaluate(x_test,y_test,batch_size=32,verbose=1)

plt.plot(history.history['loss'], label='Training loss') #this plot the loss for every epoch our model is trained on
plt.plot(history.history['val_loss'], label='Validation loss') #plots val_loss for each epoch
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='Training accuracy') 
plt.plot(history.history['val_accuracy'], label='Validation accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()
